{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "- PCA (Principle Component Analysis) finds directions of maximum variances\n",
    "- The first principal component of the data is the direction in which the data varies the most\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 2)\n",
      "(13125, 60)\n",
      "(60, 13125)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Read the data\n",
    "seeds_df = pd.read_csv(\"datasets/Grains/seeds-width-vs-length.csv\", header=None)\n",
    "wiki_df = pd.read_csv(\"datasets/Wikipedia/wikipedia-vectors.csv\", index_col=0)\n",
    "print(seeds_df.shape)\n",
    "seeds = seeds_df.values\n",
    "#Sparse matrix\n",
    "articles = csr_matrix(wiki_df.transpose())\n",
    "titles = list(wiki_df.columns)\n",
    "print(wiki_df.shape)\n",
    "print(articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 0th column of grains: width\n",
    "width = seeds[:, 0]\n",
    "\n",
    "# Assign the 1st column of grains: length\n",
    "length = seeds[:, 1]\n",
    "\n",
    "# Scatter plot width vs length\n",
    "plt.scatter(width, length)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Pearson correlation\n",
    "correlation, pvalue = pearsonr(width, length)\n",
    "\n",
    "# Display the correlation\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorrelate data using PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA instance: model\n",
    "model = PCA()\n",
    "\n",
    "# Apply the fit_transform method of model to grains: pca_features\n",
    "pca_features = model.fit_transform(seeds)\n",
    "\n",
    "# Assign 0th column of pca_features: xs\n",
    "xs = pca_features[:, 0]\n",
    "\n",
    "# Assign 1st column of pca_features: ys\n",
    "ys = pca_features[:, 1]\n",
    "\n",
    "# Scatter plot xs vs ys\n",
    "plt.scatter(xs, ys)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Pearson correlation of xs and ys\n",
    "correlation, pvalue = pearsonr(xs, ys)\n",
    "\n",
    "# Display the correlation\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrensic Dimension\n",
    "\n",
    "- PCA identify Intrensic dimension\n",
    "- Intrensic dimension = number of PCA features with significant variances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the first principle component\n",
    "\n",
    "- The first principal component of the data is the direction in which the data varies the most\n",
    "- The principal components obtained from the fitted PCA model are printed. These are the eigenvectors that represent the directions of maximum variance in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot of the untransformed points\n",
    "plt.scatter(seeds[:, 0], seeds[:, 1])\n",
    "\n",
    "# Create a PCA instance: model\n",
    "model = PCA()\n",
    "\n",
    "# Fit model to points\n",
    "model.fit(seeds)\n",
    "\n",
    "# Get the mean of the grain samples: mean\n",
    "mean = model.mean_\n",
    "\n",
    "# Get the first principal component: first_pc\n",
    "first_pc = model.components_[0, :]\n",
    "\n",
    "# Plot first_pc as an arrow, starting at mean\n",
    "plt.arrow(mean[0], mean[1], first_pc[0], first_pc[1], color=\"red\", width=0.01)\n",
    "\n",
    "# Keep axes on same scale\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance of the PCA features\n",
    "\n",
    "- This Example has 1 intrensic dimension, the one with the largest variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, pca)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline.fit(seeds)\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel(\"PCA feature\")\n",
    "plt.ylabel(\"variance\")\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction with PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA model with 1 components: pca\n",
    "pca = PCA(n_components=1)\n",
    "\n",
    "# Fit the PCA instance to the scaled samples\n",
    "pca.fit(seeds)\n",
    "\n",
    "# Transform the scaled samples: pca_features\n",
    "pca_features = pca.transform(seeds)\n",
    "\n",
    "# Print the shape of pca_features\n",
    "print(pca_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "    label                                        article\n",
      "59      0                                    Adam Levine\n",
      "50      0                                   Chad Kroeger\n",
      "51      0                                     Nate Ruess\n",
      "58      0                                         Sepsis\n",
      "54      0                                 Arctic Monkeys\n",
      "53      0                                   Stevie Nicks\n",
      "55      0                                  Black Sabbath\n",
      "56      0                                       Skrillex\n",
      "57      0                          Red Hot Chili Peppers\n",
      "52      0                                     The Wanted\n",
      "42      1                                    Doxycycline\n",
      "44      1                                           Gout\n",
      "45      1                                    Hepatitis C\n",
      "46      1                                     Prednisone\n",
      "47      1                                          Fever\n",
      "48      1                                     Gabapentin\n",
      "49      1                                       Lymphoma\n",
      "43      1                                       Leukemia\n",
      "40      1                                    Tonsillitis\n",
      "41      1                                    Hepatitis B\n",
      "9       1                                       LinkedIn\n",
      "7       1                                  Social search\n",
      "5       1                                         Tumblr\n",
      "4       1                                  Google Search\n",
      "19      2  2007 United Nations Climate Change Conference\n",
      "17      2  Greenhouse gas emissions by the United States\n",
      "15      2                                 Kyoto Protocol\n",
      "14      2                                 Climate change\n",
      "13      2                               Connie Hedegaard\n",
      "12      2                                   Nigel Lawson\n",
      "11      2       Nationally Appropriate Mitigation Action\n",
      "10      2                                 Global warming\n",
      "18      2  2010 United Nations Climate Change Conference\n",
      "16      2                                        350.org\n",
      "29      3                               Jennifer Aniston\n",
      "25      3                                  Russell Crowe\n",
      "20      3                                 Angelina Jolie\n",
      "21      3                             Michael Fassbender\n",
      "22      3                              Denzel Washington\n",
      "23      3                           Catherine Zeta-Jones\n",
      "24      3                                   Jessica Biel\n",
      "26      3                                     Mila Kunis\n",
      "27      3                                 Dakota Fanning\n",
      "28      3                                  Anne Hathaway\n",
      "34      4                             Zlatan Ibrahimović\n",
      "35      4                Colombia national football team\n",
      "31      4                              Cristiano Ronaldo\n",
      "32      4                                   Arsenal F.C.\n",
      "33      4                                 Radamel Falcao\n",
      "39      4                                  Franck Ribéry\n",
      "38      4                                         Neymar\n",
      "37      4                                       Football\n",
      "36      4              2014 FIFA World Cup qualification\n",
      "30      4                  France national football team\n",
      "8       5                                        Firefox\n",
      "6       5                    Hypertext Transfer Protocol\n",
      "3       5                                    HTTP cookie\n",
      "2       5                              Internet Explorer\n",
      "1       5                                 Alexa Internet\n",
      "0       5                                       HTTP 404\n"
     ]
    }
   ],
   "source": [
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)\n",
    "\n",
    "# Fit the pipeline to articles\n",
    "pipeline.fit(articles)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(articles)\n",
    "\n",
    "# Create a DataFrame aligning labels and titles: df\n",
    "df = pd.DataFrame({\"label\": labels, \"article\": titles})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df.sort_values(\"label\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
